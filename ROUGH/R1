package com.personalcapital.cache.aop;

import java.lang.reflect.Method;
import java.util.ArrayList;
import java.util.Collection;
import java.util.List;
import java.util.concurrent.TimeUnit;

import org.apache.commons.lang3.ObjectUtils;
import org.apache.commons.lang3.StringUtils;
import org.apache.commons.lang3.exception.ExceptionUtils;
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.springframework.aop.AopInvocationException;
import org.springframework.beans.PropertyAccessorFactory;
import org.springframework.context.EmbeddedValueResolverAware;
import org.springframework.core.annotation.Order;
import org.springframework.util.StringValueResolver;

import com.personalcapital.cache.annotation.PcapCacheable;
import com.personalcapital.cache.annotation.RedisType;
import com.personalcapital.cache.aop.support.AnnotationOrderConstants;
import com.personalcapital.cache.aop.support.CacheAdviceHelper;
import com.personalcapital.cache.aop.support.CacheKeyProvider;
import com.personalcapital.cache.utils.CacheUtils;
import com.personalcapital.log.PcapLogger;
import com.personalcapital.log.PcapLoggerFactory;
import com.safepage.util.Utils;
import io.micrometer.core.instrument.Metrics;

@Aspect
@Order(AnnotationOrderConstants.CACHE_MULTI_CACHING_PRECEDENCE)
public class PcapCacheableAdvice extends CacheAdviceCommons implements EmbeddedValueResolverAware
{
	private static final PcapLogger logger = PcapLoggerFactory
			.getPcapLogger(PcapCacheableAdvice.class);

	private StringValueResolver stringValueResolver;

	private static final String METRIC_NAME = "pcap.cache.event";

	void publishCacheMetrics(ProceedingJoinPoint pjp, String outcome)
	{
		boolean isMetricsEnabled = Boolean
				.parseBoolean(System.getProperty("cache.metrics.enabled", "true"));
		if (!isMetricsEnabled)
		{
			logger.info("Cache metrics are disabled, skipping metrics publication");
			return;
		}
		String className = getClassName(pjp);
		String methodName = getMethodName(pjp);

		Metrics.counter(METRIC_NAME, "class", className, "method", methodName, "outcome", outcome)
				.increment();
		logger.info("Publishing cache metrics - Class: {}, Method: {}, Outcome: {}", className,
				methodName, outcome);
	}

	private String getClassName(ProceedingJoinPoint pjp)
	{
		return pjp.getTarget()
				.getClass()
				.getSimpleName();
	}

	private String getMethodName(ProceedingJoinPoint pjp)
	{
		return pjp.getSignature()
				.getName();
	}

	@Around("@annotation(pcapCacheable)")
	public Object doPcapCacheable(ProceedingJoinPoint pjp, PcapCacheable pcapCacheable)
			throws Throwable
	{
		Method method = null;
		Object[] args = pjp.getArgs();
		Class<?> returnType = null;

		Collection<Object> keyArgs = null;

		String resultKeyField = pcapCacheable.resultKeyField();
		String[] resultKeyFields = pcapCacheable.resultKeyFields();

		boolean cachedValueNullable = pcapCacheable.nullable();
		String keyPrefix = pcapCacheable.keyPrefix();
		CacheKeyProvider cacheKeyProvider = null;
		// get type of cache: default or redis or simple from annotation
		String cacheName = pcapCacheable.value();
		RedisType redisType = pcapCacheable.redisType();
		String key = "";
		if (StringUtils.isBlank(cacheName))
		{
			throw new AopInvocationException(
					"PcapCacheable needs to have cacheName specified in value element.");
		}

		try
		{
			cacheKeyProvider = pcapCacheable.keyProvider()
					.getDeclaredConstructor()
					.newInstance();
			method = CacheAdviceHelper.getMethod(pjp);
			returnType = method.getReturnType();

			// check expected return type
			if (returnType.equals(Void.TYPE))
			{
				throw new AopInvocationException(
						"PcapCacheable cannot apply to method without return.");
			}

			// check if keyIndices are provided for keyName generation
			int[] keyIndice = pcapCacheable.keys();

			// get Arguments to generate key
			if (args == null || args.length == 0)
			{
				key = CacheUtils.generateKey(cacheName, keyPrefix, null);
			}
			else
			{
				keyArgs = new ArrayList<Object>();
				if (keyIndice == null || keyIndice.length == 0)
				{
					for (int i = 0; i < args.length; i++)
					{
						Object arg = args[i];
						keyArgs.add(cacheKeyProvider.getKeyField(arg));
					}
				}
				else
				{
					// if we provide a list of indices for the args that have to be used for keys,
					// use
					// this to generate keys
					for (int keyIndex : keyIndice)
					{
						if (keyIndex >= args.length)
							continue;

						Object arg = args[keyIndex];

						keyArgs.add(cacheKeyProvider.getKeyField(arg));
					}
				}

				// get key generated from all values gathered so far
				key = CacheUtils.generateKey(cacheName, keyPrefix, keyArgs);
			}
			// get cachedValue
			Object cachedValue = getRedisson(redisType).getBucket(key)
					.get();
			if (!(cachedValue == null
					|| (cachedValue instanceof ObjectUtils.Null && cachedValueNullable == false)))
			{
				publishCacheMetrics(pjp, "hit");
				return CacheUtils.getValue(cachedValue);
			}
		}
		catch (Exception ex)
		{
			logger.info("Caching on {} aborted due to an error. message: {}. stacktrace: {}",
					pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
			publishCacheMetrics(pjp, "failure");
			// PLAT-849 evictFrom redis on exception and proceeds to populate in subsequent call
			if (!evictFromRedis(redisType, key))
			{
				// if eviction fails we fetch from db and return
				return pjp.proceed();
			}
		}

		final Object resultItemForMissed = pjp.proceed(args);
		publishCacheMetrics(pjp, "miss");

		if (resultItemForMissed == null && cachedValueNullable == false)
		{
			return resultItemForMissed;
		}

		int ttl = pcapCacheable.ttlSeconds();
		final String ttlExpression = pcapCacheable.ttlExpression();

		int ttlSeconds = resolveTtl(ttlExpression, cacheName, ttl);

		try
		{
			// check if something from the result has to be used as part of the key.
			if (Utils.isNotNull(resultKeyField)
					|| (resultKeyFields != null && resultKeyFields.length > 0))
			{
				// cannot cache null value if result is used for key provider
				if (resultItemForMissed == null)
				{
					return resultItemForMissed;
				}

				List<Object> keyFieldValues = new ArrayList<Object>();

				if ((resultKeyFields != null && resultKeyFields.length > 0))
				{
					// if key is to be derived from result, then get the field from result
					// using reflection and create the cache key
					for (int i = 0; i < resultKeyFields.length; i++)
					{
						Object keyFieldValue = PropertyAccessorFactory
								.forBeanPropertyAccess(resultItemForMissed)
								.getPropertyValue(resultKeyFields[i]);
						keyFieldValues.add(cacheKeyProvider.getKeyField(keyFieldValue));
					}
				}
				else
				{// is only one is property is given use that value for key directly
					Object keyFieldValue = PropertyAccessorFactory
							.forBeanPropertyAccess(resultItemForMissed)
							.getPropertyValue(resultKeyField);

					if (keyFieldValue != null)
					{
						keyFieldValues.add(cacheKeyProvider.getKeyField(keyFieldValue));
					}
				}

				// genearteKey and add the item fetched from db.
				if (keyFieldValues.size() > 0)
				{
					String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix, keyFieldValues,
							keyArgs);
					getRedisson(redisType).getBucket(cacheKey)
							.set(resultItemForMissed, ttlSeconds, TimeUnit.SECONDS);
					publishCacheMetrics(pjp, "store");
				}
			}
			else
			{
				String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix, keyArgs);
				getRedisson(redisType).getBucket(cacheKey)
						.set(resultItemForMissed == null ? ObjectUtils.NULL : resultItemForMissed,
								ttlSeconds, TimeUnit.SECONDS);
				publishCacheMetrics(pjp, "store");
			}
		}
		catch (Exception ex)
		{
			logger.info("Caching on {} aborted due to an error. message: {}. stacktrace: {}",
					pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
			publishCacheMetrics(pjp, "failure");
		}

		return resultItemForMissed;
	}

	private int resolveTtl(String ttlExpression, String cacheName, int ttl)
	{
		Integer fromProperty = null;
		if (StringUtils.isNotBlank(ttlExpression))
		{
			try
			{
				String stringValue = stringValueResolver.resolveStringValue(ttlExpression);
				if (stringValue != null)
				{
					fromProperty = Integer.parseInt(stringValue);
				}
			}
			catch (Exception e)
			{
				logger.error("Exception resolving ttl {} for cache name {}", ttlExpression,
						cacheName);
			}
		}
		return fromProperty == null ? getTtlFromConfiguration(cacheName, ttl) : fromProperty;
	}

	@Override
	public void setEmbeddedValueResolver(StringValueResolver stringValueResolver)
	{
		this.stringValueResolver = stringValueResolver;
	}
}


in this above code, can you analyse if the below snippet is correct:
				// genearteKey and add the item fetched from db.
				if (keyFieldValues.size() > 0)
				{
					String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix, keyFieldValues,
							keyArgs);
					getRedisson(redisType).getBucket(cacheKey)
							.set(resultItemForMissed, ttlSeconds, TimeUnit.SECONDS);
					publishCacheMetrics(pjp, "store");
				}
			}
			else			
			{
				String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix, keyArgs);
				getRedisson(redisType).getBucket(cacheKey)
						.set(resultItemForMissed == null ? ObjectUtils.NULL : resultItemForMissed,
								ttlSeconds, TimeUnit.SECONDS);
				publishCacheMetrics(pjp, "store");
			}
		}
		catch (Exception ex)
		{
			logger.info("Caching on {} aborted due to an error. message: {}. stacktrace: {}",
					pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
			publishCacheMetrics(pjp, "failure");
		}

the placement of "publishCacheMetrics(pjp, "store");"

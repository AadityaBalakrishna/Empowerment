#!/bin/sh
 
set -e
echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
echo "Installation of MySQL database schema for local development (only minimum schema import)."
echo "Ensure that you have taken a backup of existing schema, as this script does not support incremental updates."
echo "TODO: Should we download all the schema ? Can we make it better ? "
echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"

DBDUMPFOLDER=~/Downloads/dbdump
rm -rf $DBDUMPFOLDER
mkdir -p "$DBDUMPFOLDER"
mkdir -p $DBDUMPFOLDER/log

saml2aws login -a $AWS_PROFILE

DBDUMP=$(aws s3 ls s3://pcap-dev-devtrunk-database-dump/data/ | grep -e 'PRE [0-9]*' | tail -1 | tr -s ' ' | cut -d ' ' -f 3)

echo "Get the latest folder ... $DBDUMP"
echo " "
echo "Download the dumps to a local folder ..."

LATESTDUMPS=pcap-dev-devtrunk-database-dump/data/$DBDUMP

aws s3 cp --recursive s3://$LATESTDUMPS $DBDUMPFOLDER
echo "Gunzip the files ..."
cd $DBDUMPFOLDER && gunzip *.gz

PASSWORD=PersonalCapital2020

echo "Create the SQL to create the schemas and users ..."
cat << EOF > $DBDUMPFOLDER/createdb.sql
    create database IF NOT EXISTS sp_schema;
    create database IF NOT EXISTS pcap_ace;
    create database IF NOT EXISTS pcap_fp;
    create database IF NOT EXISTS pcap_fp_snapshot;
    create database IF NOT EXISTS pcap_referral;
    create database IF NOT EXISTS pcap_analytics;
    create database IF NOT EXISTS pcapaudit_schema;
    create database IF NOT EXISTS pcap_pcb;
    create database IF NOT EXISTS pcap_snapshot;
    create database IF NOT EXISTS pcap_transaction;
    create database IF NOT EXISTS pcap_privacy;
    create database IF NOT EXISTS pcap_batch;
    create database IF NOT EXISTS pcap_empower;
    create database IF NOT EXISTS pcap_payment;
    create database IF NOT EXISTS pcap_feex;
    create database IF NOT EXISTS epw_aggregation;
    create database IF NOT EXISTS user_response;
    create database IF NOT EXISTS pcap_cq;
    create database IF NOT EXISTS pcap_vca;
    create database IF NOT EXISTS epw_account;
    CREATE USER IF NOT EXISTS 'spdbapp'@'%' IDENTIFIED BY '$PASSWORD';
    CREATE USER IF NOT EXISTS 'pcbappuser'@'%' IDENTIFIED BY '$PASSWORD';
    CREATE USER IF NOT EXISTS 'pcb_app_1'@'%' IDENTIFIED BY '$PASSWORD';
    CREATE USER IF NOT EXISTS 'pcap_app_2'@'%' IDENTIFIED BY '$PASSWORD';
    CREATE USER IF NOT EXISTS 'batch_app_1'@'%' IDENTIFIED BY '$PASSWORD';
    CREATE USER IF NOT EXISTS 'aggr_app_1'@'%' IDENTIFIED BY '$PASSWORD';
    CREATE USER IF NOT EXISTS 'dbadmin'@'%' IDENTIFIED BY '$PASSWORD';
    CREATE USER IF NOT EXISTS 'batch_app_1'@'%' IDENTIFIED BY '$PASSWORD';
    CREATE USER IF NOT EXISTS 'trxn_app_1'@'%' IDENTIFIED BY '$PASSWORD';
    GRANT ALL PRIVILEGES ON *.* TO 'spdbapp'@'%';
    GRANT ALL PRIVILEGES ON *.* TO 'pcap_app_2'@'%';
    GRANT ALL PRIVILEGES ON pcap_pcb.* TO 'pcbappuser'@'%';
    GRANT ALL PRIVILEGES ON pcap_pcb.* TO 'pcb_app_1'@'%';
    GRANT ALL PRIVILEGES ON pcap_snapshot.* TO 'spdbapp'@'%';
    GRANT ALL PRIVILEGES ON pcap_transaction.* TO 'spdbapp'@'%';
    GRANT ALL PRIVILEGES ON pcap_privacy.* TO 'spdbapp'@'%';
    GRANT ALL PRIVILEGES ON pcap_batch.* TO 'spdbapp'@'%';
    GRANT ALL PRIVILEGES ON pcap_batch.* TO 'batch_app_1'@'%';
    GRANT ALL PRIVILEGES ON pcap_snapshot.* TO 'pcap_app_2'@'%';
    GRANT ALL PRIVILEGES ON *.* TO 'aggr_app_1'@'%';
    GRANT ALL PRIVILEGES ON *.* TO 'dbadmin'@'%';
    GRANT ALL PRIVILEGES ON *.* TO 'batch_app_1'@'%';
    GRANT ALL PRIVILEGES ON *.* TO 'trxn_app_1'@'%';
    FLUSH PRIVILEGES;
EOF

echo "Creating schema and users in mysql ..."
HOST=127.0.0.1
PORT=3305

mysql -h $HOST -P $PORT -u root -padmin < $DBDUMPFOLDER/createdb.sql  > $DBDUMPFOLDER/log/dbcreation.log 2>&1

# list schemas from smallest to largest

DBFILE=(
  "pcap_vca"
  "pcap_payment"
  "user_response"
  "pcap_cq"
  "epw_aggregation"
  "pcap_referral"
  "pcap_feex"
  "pcap_analytics"
  "pcap_fp_snapshot"
  "pcap_fp"
  "pcap_batch"
  "pcap_pcb"
  "pcap_privacy"
  "epw_account"
  "pcap_snapshot"
  "pcap_empower"
  "sp_schema"
)
datedotsql=`echo $DBDUMP | sed  's/\//.sql/g'`

cd $DBDUMPFOLDER

for db in ${DBFILE[@]}; do
    echo "Would you like to import schema $db ? (Y/n)"
    read imprt
    if [ $imprt = "y" ] || [ $imprt = "Y" ];
      then
        echo "Importing schema $db ... from " "$db""$datedotsql"
        mysql -h $HOST -P $PORT -u root -padmin $db < "$db""$datedotsql" > "$DBDUMPFOLDER/log/$datedotsql"".log" 2>&1
    fi
done

echo "DONE!!"

#!/bin/sh
 
set -e
echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
echo " "
echo "Download of mySql database schema for local development . This download minimum to start up application" 
echo "Ensure that u have taken a backup of existing schema, this script doesnot support incremental update"
echo "TODO: Should we download all the schema ? Can we make it better ? "
echo "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"

DBDUMPFOLDER=~/Downloads/dbdump
LOGFILE="$DBDUMPFOLDER/log/missing_files.log"
mkdir -p "$DBDUMPFOLDER"
rm -rf "$DBDUMPFOLDER"
mkdir -p "$DBDUMPFOLDER/log"

# Get the latest folder from S3
DBDUMP=$(aws s3 ls s3://pcap-dev-devtrunk-database-dump/data/ | grep ' PRE ' | tail -1 | awk '{print $2}')

echo "Get the latest folder ... $DBDUMP"
echo " "
echo "Download the dumps to a local folder ..."

LATESTDUMPS=pcap-dev-devtrunk-database-dump/data/$DBDUMP

# Array of file patterns to download
FILE_PATTERNS=(
	"pcapaudit_schema*.gz"
	"sp_schema*.gz"
	"pcap_fp*.gz"
	"pcap_fp_snapshot*.gz"
	"pcap_referral*.gz"
	"pcap_pcb*.gz"
	"pcap_snapshot*.gz"
	"pcap_analytics*.gz"
	"pcap_transaction*.gz"
	"pcap_privacy*.gz"
	"pcap_batch*.gz"
	"pcap_empower*.gz"
	"pcap_vca*.gz"
	"pcap_payment*.gz"
	"pcap_feex*.gz"
	"epw_aggregation*.gz"
	"epw_account*.gz"
	"user_response*.gz"
	"pcap_cq*.gz"
)

# Download files and log missing files
for pattern in "${FILE_PATTERNS[@]}"; do
    echo "Trying to download: $pattern"
    if ! aws s3 cp --recursive --exclude "*" --include "$pattern" s3://$LATESTDUMPS "$DBDUMPFOLDER"; then
        echo "No files matching $pattern found in $LATESTDUMPS." >> "$LOGFILE"
    fi
done

echo "DONE!!"


can you refactor these two files such that i download only sp_schema and install only that db?


		// get type of cache: default or redis or simple from annotation
		if (StringUtils.isBlank(cacheName))
		{
			throw new AopInvocationException(
					"pcapMultiCacheable needs to have cacheName specified in value element.");
		}
		CacheKeyProvider cacheKeyProvider = pcapMultiCacheable.keyProvider()
				.getDeclaredConstructor()
				.newInstance();
		try
		{
			method = CacheAdviceHelper.getMethod(pjp);
			returnType = method.getReturnType();

			// check expected return type
			if (Collection.class.isAssignableFrom(returnType))
			{
				resultIsCollection = true;
				collectionResult = collectionInstance((Class<? extends Collection>) returnType);
			}
			else if (Map.class.isAssignableFrom(returnType))
			{
				resultIsCollection = false;
				mapResult = mapInstance((Class<? extends Map>) returnType);
			}
			else
			{
				throw new AopInvocationException(
						"pcapMultiCacheable cannot apply to method without return.");
			}

			// check if keyIndices are provided for keyName generation
			int[] keyIndice = pcapMultiCacheable.keys();

			if (args == null || args.length == 0)
			{
				throw new AopInvocationException(
						"pcapMultiCacheable cannot apply to method without parameter");
			}

			// get other Arguments to generate key
			if (keyIndice == null || keyIndice.length == 0)
			{
				for (int i = 0; i < args.length; i++)
				{
					Object arg = args[i];
					/*
					 * if arguments contain a collection, remember the argument number tp extract
					 * elements for keyName generation later
					 */
					if (Collection.class.isInstance(arg)
							&& Collection.class.isAssignableFrom(arg.getClass()))
					{
						listKeyArgIndex = i;
					}
					else
					{
						otherKeyArgs.add(cacheKeyProvider.getKeyField(arg));
					}
				}
			}
			else
			{
				// if we provide a list of indices for the args that have to be used for keys, use
				// this to generate keys
				for (int keyIndex : keyIndice)
				{
					if (keyIndex >= args.length)
						continue;

					Object arg = args[keyIndex];
					if (Collection.class.isInstance(arg)
							&& Collection.class.isAssignableFrom(arg.getClass()))
					{
						listKeyArgIndex = keyIndex;
					}
					else
					{
						otherKeyArgs.add(cacheKeyProvider.getKeyField(arg));
					}
				}
			}

			if (listKeyArgIndex == null)
			{
				throw new AopInvocationException(
						"pcapMultiCacheable must have a Collection parameter as key list");
			}

			// get the collection arg to generate keys
			listKeyArg = (Collection<Object>) args[listKeyArgIndex];
			for (Object listKey : listKeyArg)
			{
				// get key generated from all values gathered so far from pcapMultiCacheable
				String key = CacheUtils.generateKey(cacheName, keyPrefix,
						cacheKeyProvider.getKeyField(listKey), otherKeyArgs);
				// get cachedValue
				Object cachedValue = getRedisson(redisType).getBucket(key)
						.get();
				if (cachedValue == null || (cachedValue instanceof ObjectUtils.Null
						&& cachedValueNullable == false))
				{
					if (missedListKeys == null)
					{
						// create an empty collection of type of expected cachedValues
						missedListKeys = collectionInstance(listKeyArg.getClass());
					}

					// create a collection of keys with no cachedValues
					((Collection<Object>) missedListKeys).add(listKey);
					// Cache Miss Metric
					publishCacheMetrics(pjp, "miss");
				}
				else
				{
					// write keys and corresponding cached values to a keyValue Map
					((Map<Object, Object>) keyValueMap).put(listKey,
							CacheUtils.getValue(cachedValue));
					// Cache Hit Metric
					publishCacheMetrics(pjp, "hit");
				}
			}

			// if there are no missed keys just return all the values fetched from cache
			if (missedListKeys == null || missedListKeys.isEmpty())
			{
				if (resultIsCollection)
					return getCollectionResult(listKeyArg, keyValueMap, collectionResult);
				else
					return getMapResult(listKeyArg, keyValueMap, mapResult);
			}

			// here we update the arguments for the method to only get those records from the db for
			// which we didn't find an entry in the cache.
			modifiedArgs = modifiedArgs(args, listKeyArgIndex, missedListKeys);
		}
		catch (Exception ex)
		{
			logger.info("Caching on {} aborted due to an error. message: {}. stacktrace: {}",
					pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
			// Cache Failure Metric
			publishCacheMetrics(pjp, "failure");
			try
			{
				final CacheKeyProvider finalCacheKeyProvider = cacheKeyProvider;
				final Collection<Object> finalOtherKeyArgs = otherKeyArgs;
				List<String> keys = listKeyArg.stream()
						.filter(k -> Objects.nonNull(k))
						.map(k -> CacheUtils.generateKey(cacheName, keyPrefix,
								finalCacheKeyProvider.getKeyField(k), finalOtherKeyArgs))
						.collect(Collectors.toList());
				if (!evictFromRedis(redisType, keys))
				{
					// if eviction fails we fetch from db and return
					return pjp.proceed();
				}
			}
			catch (Exception e)
			{
				logger.info("Eviction on caching failure failed on {}, due to: {}, stacktrace: {}",
						pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
				// Cache Eviction Failure Metric
				publishCacheMetrics(pjp, "eviction_failure");
			}
			// since we evict all the keys we want to fetch and save all the keys again
			modifiedArgs = args;
		}

i'm giving you the entire block of code to get to that data_eviction stage, mock the exception properly and get me the right answe

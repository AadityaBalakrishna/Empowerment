package com.personalcapital.cache.aop;

import java.lang.reflect.Method;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

import org.apache.commons.lang3.ObjectUtils;
import org.apache.commons.lang3.StringUtils;
import org.apache.commons.lang3.exception.ExceptionUtils;
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.springframework.aop.AopInvocationException;
import org.springframework.beans.PropertyAccessorFactory;
import org.springframework.core.annotation.Order;

import com.personalcapital.cache.annotation.PcapMultiCacheable;
import com.personalcapital.cache.annotation.RedisType;
import com.personalcapital.cache.aop.support.AnnotationOrderConstants;
import com.personalcapital.cache.aop.support.CacheAdviceHelper;
import com.personalcapital.cache.aop.support.CacheKeyProvider;
import com.personalcapital.cache.utils.CacheUtils;
import com.personalcapital.log.PcapLogger;
import com.personalcapital.log.PcapLoggerFactory;
import com.safepage.util.Utils;
import io.micrometer.core.instrument.Metrics;

@Aspect
@Order(AnnotationOrderConstants.CACHE_MULTI_CACHING_PRECEDENCE)
public class PcapMultiCacheableAdvice extends CacheAdviceCommons
{
	private static final PcapLogger logger = PcapLoggerFactory
			.getPcapLogger(PcapMultiCacheableAdvice.class);
	private static final String METRICS_NAME = "pcap.cache.event";

	void publishCacheMetrics(ProceedingJoinPoint pjp, String outcome)
	{
		String className = getClassName(pjp);
		String methodName = getMethodName(pjp);

		Metrics.counter(METRICS_NAME, "class", className, "method", methodName, "outcome", outcome)
				.increment();
	}

	private String getClassName(ProceedingJoinPoint pjp)
	{
		return pjp.getTarget()
				.getClass()
				.getSimpleName();
	}

	private String getMethodName(ProceedingJoinPoint pjp)
	{
		return pjp.getSignature()
				.getName();
	}

	@SuppressWarnings("unchecked")
	@Around("@annotation(pcapMultiCacheable)")
	public Object doMultiCacheable(ProceedingJoinPoint pjp, PcapMultiCacheable pcapMultiCacheable)
			throws Throwable
	{
		String className = getClassName(pjp);
		String methodName = getMethodName(pjp);

		Method method = null;
		Object[] args = pjp.getArgs();
		Class<?> returnType = null;
		Integer listKeyArgIndex = null;
		Collection<Object> listKeyArg = new ArrayList<Object>();
		Collection<Object> otherKeyArgs = new ArrayList<Object>();

		Collection<Object> missedListKeys = null;
		Object[] modifiedArgs = null;
		boolean resultIsCollection = true;

		String resultKeyField = pcapMultiCacheable.resultKeyField();
		String[] resultKeyFields = pcapMultiCacheable.resultKeyFields();

		boolean cachedValueNullable = pcapMultiCacheable.nullable();
		String keyPrefix = pcapMultiCacheable.keyPrefix();
		Collection<Object> collectionResult = null;
		Map<Object, Object> mapResult = null;

		Map<Object, Object> keyValueMap = new LinkedHashMap<>();
		String cacheName = pcapMultiCacheable.value();
		RedisType redisType = pcapMultiCacheable.redisType();
		// get type of cache: default or redis or simple from annotation
		if (StringUtils.isBlank(cacheName))
		{
			throw new AopInvocationException(
					"pcapMultiCacheable needs to have cacheName specified in value element.");
		}
		CacheKeyProvider cacheKeyProvider = pcapMultiCacheable.keyProvider()
				.getDeclaredConstructor()
				.newInstance();
		try
		{
			method = CacheAdviceHelper.getMethod(pjp);
			returnType = method.getReturnType();

			// check expected return type
			if (Collection.class.isAssignableFrom(returnType))
			{
				resultIsCollection = true;
				collectionResult = collectionInstance((Class<? extends Collection>) returnType);
			}
			else if (Map.class.isAssignableFrom(returnType))
			{
				resultIsCollection = false;
				mapResult = mapInstance((Class<? extends Map>) returnType);
			}
			else
			{
				throw new AopInvocationException(
						"pcapMultiCacheable cannot apply to method without return.");
			}

			// check if keyIndices are provided for keyName generation
			int[] keyIndice = pcapMultiCacheable.keys();

			if (args == null || args.length == 0)
			{
				throw new AopInvocationException(
						"pcapMultiCacheable cannot apply to method without parameter");
			}

			// get other Arguments to generate key
			if (keyIndice == null || keyIndice.length == 0)
			{
				for (int i = 0; i < args.length; i++)
				{
					Object arg = args[i];
					/*
					 * if arguments contain a collection, remember the argument number tp extract
					 * elements for keyName generation later
					 */
					if (Collection.class.isInstance(arg)
							&& Collection.class.isAssignableFrom(arg.getClass()))
					{
						listKeyArgIndex = i;
					}
					else
					{
						otherKeyArgs.add(cacheKeyProvider.getKeyField(arg));
					}
				}
			}
			else
			{
				// if we provide a list of indices for the args that have to be used for keys, use
				// this to generate keys
				for (int keyIndex : keyIndice)
				{
					if (keyIndex >= args.length)
						continue;

					Object arg = args[keyIndex];
					if (Collection.class.isInstance(arg)
							&& Collection.class.isAssignableFrom(arg.getClass()))
					{
						listKeyArgIndex = keyIndex;
					}
					else
					{
						otherKeyArgs.add(cacheKeyProvider.getKeyField(arg));
					}
				}
			}

			if (listKeyArgIndex == null)
			{
				throw new AopInvocationException(
						"pcapMultiCacheable must have a Collection parameter as key list");
			}

			// get the collection arg to generate keys
			listKeyArg = (Collection<Object>) args[listKeyArgIndex];
			for (Object listKey : listKeyArg)
			{
				// get key generated from all values gathered so far from pcapMultiCacheable
				String key = CacheUtils.generateKey(cacheName, keyPrefix,
						cacheKeyProvider.getKeyField(listKey), otherKeyArgs);
				// get cachedValue
				Object cachedValue = getRedisson(redisType).getBucket(key)
						.get();
				if (cachedValue == null || (cachedValue instanceof ObjectUtils.Null
						&& cachedValueNullable == false))
				{
					if (missedListKeys == null)
					{
						// create an empty collection of type of expected cachedValues
						missedListKeys = collectionInstance(listKeyArg.getClass());
					}

					// create a collection of keys with no cachedValues
					((Collection<Object>) missedListKeys).add(listKey);
					// Cache Miss Metric
					publishCacheMetrics(pjp, "miss");
				}
				else
				{
					// write keys and corresponding cached values to a keyValue Map
					((Map<Object, Object>) keyValueMap).put(listKey,
							CacheUtils.getValue(cachedValue));
					// Cache Hit Metric
					publishCacheMetrics(pjp, "hit");
				}
			}

			// if there are no missed keys just return all the values fetched from cache
			if (missedListKeys == null || missedListKeys.isEmpty())
			{
				if (resultIsCollection)
					return getCollectionResult(listKeyArg, keyValueMap, collectionResult);
				else
					return getMapResult(listKeyArg, keyValueMap, mapResult);
			}

			// here we update the arguments for the method to only get those records from the db for
			// which we didn't find an entry in the cache.
			modifiedArgs = modifiedArgs(args, listKeyArgIndex, missedListKeys);
		}
		catch (Exception ex)
		{
			logger.info("Caching on {} aborted due to an error. message: {}. stacktrace: {}",
					pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
			// Cache Failure Metric
			publishCacheMetrics(pjp, "failure");
			try
			{
				final CacheKeyProvider finalCacheKeyProvider = cacheKeyProvider;
				final Collection<Object> finalOtherKeyArgs = otherKeyArgs;
				List<String> keys = listKeyArg.stream()
						.filter(k -> Objects.nonNull(k))
						.map(k -> CacheUtils.generateKey(cacheName, keyPrefix,
								finalCacheKeyProvider.getKeyField(k), finalOtherKeyArgs))
						.collect(Collectors.toList());
				if (!evictFromRedis(redisType, keys))
				{
					// if eviction fails we fetch from db and return
					return pjp.proceed();
				}
			}
			catch (Exception e)
			{
				logger.info("Eviction on caching failure failed on {}, due to: {}, stacktrace: {}",
						pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
				// Cache Eviction Failure Metric
				publishCacheMetrics(pjp, "eviction_failure");
			}
			// since we evict all the keys we want to fetch and save all the keys again
			modifiedArgs = args;
		}

		/*
		 * so far we have created a key and gotten the corresponding cached values for these keys we
		 * also have a list of all the keys for which we don't have a value.
		 */
		final Object resultForMissed = pjp.proceed(modifiedArgs);

		int ttlSeconds = getTtlFromConfiguration(cacheName, pcapMultiCacheable.ttlSeconds());

		// we now have all the missing collection/data from the database
		try
		{
			if (resultIsCollection)
			{
				// get all the newly fetched data
				Collection<Object> collectionResultForMissed = (Collection<Object>) resultForMissed;

				// check if something from the result has to be used as part of the key.
				if (Utils.isNotNull(resultKeyField)
						|| (resultKeyFields != null && resultKeyFields.length > 0))
				{
					Collection<Object> mergedResult = getCollectionResult(listKeyArg, keyValueMap,
							collectionResult);

					// if nothing new was found for the missed keys, just return the existing
					// collection
					if (collectionResultForMissed == null || collectionResultForMissed.isEmpty())
						return mergedResult;

					List<Object> keyFieldValues = new ArrayList<Object>();

					for (Object resultItemForMissed : collectionResultForMissed)
					{
						if (resultItemForMissed == null)
							continue;

						keyFieldValues.clear();
						if ((resultKeyFields != null && resultKeyFields.length > 0))
						{
							// if key is to be derived from result, then get the field from result
							// using reflection and create the cache key
							for (int i = 0; i < resultKeyFields.length; i++)
							{
								Object keyFieldValue = PropertyAccessorFactory
										.forBeanPropertyAccess(resultItemForMissed)
										.getPropertyValue(resultKeyFields[i]);
								keyFieldValues.add(cacheKeyProvider.getKeyField(keyFieldValue));
							}
						}
						else
						{// is only one is property is given use that value for key directly
							Object keyFieldValue = PropertyAccessorFactory
									.forBeanPropertyAccess(resultItemForMissed)
									.getPropertyValue(resultKeyField);

							if (keyFieldValue != null)
							{
								keyFieldValues.add(cacheKeyProvider.getKeyField(keyFieldValue));
							}
						}

						// genearteKey and add the item fetched from db.
						if (keyFieldValues.size() > 0)
						{
							String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix,
									keyFieldValues, otherKeyArgs);
							getRedisson(redisType).getBucket(cacheKey)
									.set(resultItemForMissed, ttlSeconds, TimeUnit.SECONDS);
							// Cache Store Metric
							publishCacheMetrics(pjp, "store");
						}
						// add found item to resultant collection from cache+db that has to be
						// returned
						mergedResult.add(resultItemForMissed);
					}

					return mergedResult;
				}

				// if all the generated keys don't have a corresponding value, just generate a list
				// for the ones that do have it
				if (collectionResultForMissed == null
						|| collectionResultForMissed.size() != missedListKeys.size())
				{
					logger.warn(
							"Did not receive a correlated amount of data from the target method: {}. "
									+ "Result list will be unsorted and won't respect the order of the keys passed in argument.",
							pjp.toShortString());
					// Data Mismatch Metric
					publishCacheMetrics(pjp, "data_mismatch");
					Collection<Object> resultFromHit = getCollectionResult(listKeyArg, keyValueMap,
							collectionResult);
					if (collectionResultForMissed != null)
					{
						collectionResultForMissed.addAll(resultFromHit);
						return collectionResultForMissed;
					}
					return resultFromHit;
				}

				// if no property of the resulting objects from the object collection has to be used
				// as part of they key, simply iterate over the missedKeys and missed Values and
				// create a resultant collection and return it.

				Iterator<Object> missedValueIterator = collectionResultForMissed.iterator();
				Iterator<Object> missedKeyIterator = missedListKeys.iterator();

				while (missedKeyIterator.hasNext())
				{
					Object key = missedKeyIterator.next();
					Object value = missedValueIterator.next();

					if (value != null || cachedValueNullable)
					{
						String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix,
								cacheKeyProvider.getKeyField(key), otherKeyArgs);
						getRedisson(redisType).getBucket(cacheKey)
								.set(value == null ? ObjectUtils.NULL : value, ttlSeconds,
										TimeUnit.SECONDS);
						// Cache Store Metric
						publishCacheMetrics(pjp, "store");
					}

					keyValueMap.put(key, value);
				}

				// return a collection of missing objects
				return getCollectionResult(listKeyArg, keyValueMap, collectionResult);
			}
			else
			{
				// if result is a map and not a collection
				Map<Object, Object> mapResultForMissed = (Map<Object, Object>) resultForMissed;
				Map<Object, Object> mergedResult = getMapResult(listKeyArg, keyValueMap, mapResult);
				if (mapResultForMissed == null || mapResultForMissed.isEmpty())
				{
					return mergedResult;
				}

				Iterator<Object> missedKeyIterator = missedListKeys.iterator();

				while (missedKeyIterator.hasNext())
				{
					Object key = missedKeyIterator.next();
					Object value = mapResultForMissed.get(key);

					if (value != null || cachedValueNullable)
					{
						String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix,
								cacheKeyProvider.getKeyField(key), otherKeyArgs);
						getRedisson(redisType).getBucket(cacheKey)
								.set(value == null ? ObjectUtils.NULL : value, ttlSeconds,
										TimeUnit.SECONDS);
						// Cache Store Metric
						publishCacheMetrics(pjp, "store");
					}

					mergedResult.put(key, value);
				}

				return mergedResult;
			}
		}
		catch (Exception ex)
		{
			logger.info("Caching on {} aborted due to an error. message: {}. stacktrace: {}",
					pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
			// Cache Failure Metric
			publishCacheMetrics(pjp, "failure");

			return pjp.proceed();
		}
	}

	private Object[] modifiedArgs(final Object[] originalArgs, int listKeyIndex,
			Collection<Object> missedListKeys)
	{
		Object[] modifiedArgs = new Object[originalArgs.length];
		System.arraycopy(originalArgs, 0, modifiedArgs, 0, originalArgs.length);

		modifiedArgs[listKeyIndex] = missedListKeys;
		return modifiedArgs;
	}

	private Collection<Object> getCollectionResult(Collection<Object> listKeyArg,
			Map<Object, Object> keyValueMap, Collection<Object> collectionResult)
	{
		collectionResult.clear();

		for (Object listKey : listKeyArg)
		{
			if (keyValueMap.containsKey(listKey))
				collectionResult.add(keyValueMap.get(listKey));
		}

		return collectionResult;
	}

	/**
	 * get list of arguments and results for map and create a resultant merged cache+db map
	 * 
	 * @param listKeyArg
	 * @param keyValueMap
	 * @param mapResult
	 * @return
	 */
	private Map<Object, Object> getMapResult(Collection<Object> listKeyArg,
			Map<Object, Object> keyValueMap, Map<Object, Object> mapResult)
	{
		mapResult.clear();

		for (Object listKey : listKeyArg)
		{
			if (keyValueMap.containsKey(listKey))
				mapResult.put(listKey, keyValueMap.get(listKey));
		}

		return mapResult;
	}

	/**
	 * return a new collection instance with a given type
	 * 
	 * @param listType
	 * @return
	 */
	private Collection<Object> collectionInstance(Class<? extends Collection> listType)
	{
		Collection<Object> listInstance;

		try
		{
			listInstance = listType.getDeclaredConstructor()
					.newInstance();
		}
		catch (Throwable e)
		{
			listInstance = new ArrayList<>();
		}

		return listInstance;
	}

	/**
	 * return a new map instance of map type with given non-generic types
	 * 
	 * @param mapType
	 * @return
	 */
	private Map<Object, Object> mapInstance(Class<? extends Map> mapType)
	{
		Map<Object, Object> mapInstance;

		try
		{
			mapInstance = mapType.getDeclaredConstructor()
					.newInstance();
		}
		catch (Throwable e)
		{
			mapInstance = new LinkedHashMap<>();
		}

		return mapInstance;
	}
}


package com.personalcapital.cache.testframework;

import com.personalcapital.cache.aop.*;
import com.personalcapital.cache.config.CacheJVMConfiguration;
import com.personalcapital.cache.redis.DateRangeCacheRedisHashMapUtils;
import com.personalcapital.cache.redis.DateRangeCacheRedisSortedSetHelper;
import com.personalcapital.cache.redis.PcapCacheErrorHandler;
import com.personalcapital.cache.utils.CacheConstants;
import com.personalcapital.cache.utils.CacheManagerHelper;
import com.personalcapital.log.PcapLogger;
import com.personalcapital.log.PcapLoggerFactory;
import org.redisson.api.RedissonClient;
import org.redisson.spring.cache.CacheConfig;
import org.redisson.spring.cache.RedissonSpringCacheManager;
import org.springframework.beans.factory.annotation.Lookup;
import org.springframework.cache.CacheManager;
import org.springframework.cache.annotation.CachingConfigurerSupport;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.cache.interceptor.CacheErrorHandler;
import org.springframework.cache.transaction.TransactionAwareCacheManagerProxy;
import org.springframework.context.annotation.*;
import org.springframework.test.context.TestPropertySource;
import org.testcontainers.containers.GenericContainer;
import org.testcontainers.containers.wait.strategy.Wait;

import jakarta.annotation.PostConstruct;
import jakarta.annotation.PreDestroy;
import java.util.Map;

import static org.springframework.test.util.ReflectionTestUtils.setField;

@Configuration
@EnableAspectJAutoProxy
@EnableCaching(order = org.springframework.core.Ordered.HIGHEST_PRECEDENCE)
@ComponentScan(basePackages = { "com.personalcapital.cache.config" })
@TestPropertySource(properties =
{
        "caching.redis.readMode=MASTER",
        "caching.redis.ha.readMode=MASTER",
        "caching.redisson.idleConnectionTimeout=100",
        "caching.redisson.timeout=2000",
        "caching.redis.timeout=5000",
        "caching.redisson.timeout=5000",
        "caching.redis.pool.maxTotal=50",
        "caching.redis.pool.maxIdle=20",
        "caching.redis.pool.minIdle=5",
        "caching.redis.serializer.useMinBin=false",
        "redis.enabled=true",
        "caching.global.disabled=true",
        "caching.global.mode=redis",
        "caching.redis.hostname=127.0.0.1"
} )
@Import(CacheJVMConfiguration.class)
public class CacheTestConfiguration extends CachingConfigurerSupport
{
    private static final PcapLogger LOGGER = PcapLoggerFactory.getPcapLogger(CacheTestConfiguration.class);
    public static GenericContainer redis =
            new GenericContainer("redis:6")
                    .withExposedPorts(6379);

    public CacheTestConfiguration()
    {
    }

    @PostConstruct
    public void initialize() throws Exception
    {
        LOGGER.debug("CacheTestConfiguration Initialized---" + Thread.currentThread().getName());
        redis.withLogConsumer(new PCAPLogConsumer(LOGGER)).
        waitingFor(
            Wait.forLogMessage(".*Ready to accept connections.*\\n", 1)
        );
        redis.start();
        Thread.sleep(2000);// TODO: Handle proper container startup
        Integer firstMappedPort = redis.getMappedPort(6379);
        final String redisPort = String.valueOf(firstMappedPort);

        System.setProperty("caching.redis.port", redisPort);
        System.setProperty("caching.redis.ha.port", redisPort);
        System.setProperty("caching.redis.ha.cluster.port", redisPort);
        System.setProperty("caching.redis.cluster.port",redisPort);
        System.setProperty("caching.redis.ha.hostname","127.0.0.1");
        System.setProperty("caching.redis.ha.configEndpoint","127.0.0.1");
        System.setProperty("caching.global.uri","127.0.0.1:11211");
        System.setProperty("caching.redis.clusterMode","false");

    }
    @PreDestroy
    public void destroy() throws Exception
    {
        LOGGER.debug("CacheTestConfiguration Destroy---" + Thread.currentThread().getName());
        redis.stop();
    }
    @Lookup(value = CacheConstants.REDISSON_REGULAR)
    public RedissonClient redission(){
        return null;
    }

    @Lookup(value = CacheConstants.REDISSON_HIGH_AVAILABILITY)
    public RedissonClient redissionHa(){
        return null;
    }

    @Lookup(value = "redisCacheExpires")
    public Map<String, CacheConfig> redisCacheExpires()
    {
        return null;
    }

    @Bean
    public PcapCacheableAdvice pcapCacheableAdvice()
    {
        LOGGER.debug("Initializing PcapCacheableAdvice bean");
        PcapCacheableAdvice pcapCacheableAdvice = new PcapCacheableAdvice();
        setField(pcapCacheableAdvice, "redissonGen",redission());
        setField(pcapCacheableAdvice, "redissonHa",redissionHa());
        setField(pcapCacheableAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapCacheableAdvice bean {} " , pcapCacheableAdvice);
        return pcapCacheableAdvice;
    }

    @Bean(name = "pcapMultiCacheableAdvice")
    public PcapMultiCacheableAdvice pcapMultiCacheableAdvice()
    {
        LOGGER.debug("Initializing PcapMultiCacheableAdvice bean");
        PcapMultiCacheableAdvice pcapMultiCacheableAdvice = new PcapMultiCacheableAdvice();
        setField(pcapMultiCacheableAdvice, "redissonGen",redission());
        setField(pcapMultiCacheableAdvice, "redissonHa",redissionHa());
        setField(pcapMultiCacheableAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapCacheableAdvice bean {} " , pcapMultiCacheableAdvice);
        return pcapMultiCacheableAdvice;
    }

    @Bean(name = "pcapMultiCacheEvictAdvice")
    public PcapMultiCacheEvictAdvice pcapMultiCacheEvictAdvice()
    {
        LOGGER.debug("Initialized PcapMultiCacheEvictAdvice bean ");
        PcapMultiCacheEvictAdvice pcapMultiCacheEvictAdvice = new PcapMultiCacheEvictAdvice();
        setField(pcapMultiCacheEvictAdvice, "redissonGen",redission());
        setField(pcapMultiCacheEvictAdvice, "redissonHa",redissionHa());
        setField(pcapMultiCacheEvictAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapMultiCacheEvictAdvice bean {} " , pcapMultiCacheEvictAdvice);
        return pcapMultiCacheEvictAdvice;
    }

    @Bean(name = "pcapMultiCachePutAdvice")
    public PcapMultiCachePutAdvice pcapMultiCachePutAdvice()
    {
        LOGGER.debug("Initialized PcapMultiCachePutAdvice bean ");
        PcapMultiCachePutAdvice pcapMultiCachePutAdvice = new PcapMultiCachePutAdvice();
        setField(pcapMultiCachePutAdvice, "redissonGen",redission());
        setField(pcapMultiCachePutAdvice, "redissonHa",redissionHa());
        setField(pcapMultiCachePutAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapMultiCachePutAdvice bean {} " , pcapMultiCachePutAdvice);
        return pcapMultiCachePutAdvice;
    }

    @Bean
    public PcapCacheEvictAdvice pcapCacheEvictAdvice()
    {
        LOGGER.debug("Initialized PcapCacheEvictAdvice bean ");
        PcapCacheEvictAdvice pcapCacheableEvictAdvice = new PcapCacheEvictAdvice();
        setField(pcapCacheableEvictAdvice, "redissonGen",redission());
        setField(pcapCacheableEvictAdvice, "redissonHa",redissionHa());
        setField(pcapCacheableEvictAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapCacheEvictAdvice bean {} " , pcapCacheableEvictAdvice);
        return pcapCacheableEvictAdvice;
    }

    @Bean
    public PcapCachePutAdvice pcapCachePutAdvice()
    {
        LOGGER.debug("Initialized PcapCachePutAdvice bean " );
        PcapCachePutAdvice pcapCachePutAdvice = new PcapCachePutAdvice();
        setField(pcapCachePutAdvice, "redissonGen",redission());
        setField(pcapCachePutAdvice, "redissonHa",redissionHa());
        setField(pcapCachePutAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapCachePutAdvice bean {} ", pcapCachePutAdvice );
        return pcapCachePutAdvice;
    }


    @Bean
    public DateRangeCacheAdvice dateRangeCacheAdvice()
    {
        LOGGER.debug("Initializing DateRangeCacheAdvice bean");
        DateRangeCacheAdvice dateRangeCacheAdvice = new DateRangeCacheAdvice();
        LOGGER.debug("Initializing DateRangeCacheAdvice bean {} ", dateRangeCacheAdvice);
        return dateRangeCacheAdvice;
    }

    @Bean
    public DateRangeCacheRedisHashMapUtils dateRangeCacheRedisHashMapUtils()
    {
        LOGGER.debug("Initializing DateRangeCacheRedisHashMapUtils bean");
        DateRangeCacheRedisHashMapUtils dateRangeCacheRedisHashMapUtils = new DateRangeCacheRedisHashMapUtils();
        setField(dateRangeCacheRedisHashMapUtils, "redisson",redissionHa());
        LOGGER.debug("Initializing DateRangeCacheRedisHashMapUtils bean {}", dateRangeCacheRedisHashMapUtils);
        return dateRangeCacheRedisHashMapUtils;
    }

    @Bean
    public DateRangeCacheRedisSortedSetHelper dateRangeCacheRedisSortedSetHelper()
    {
        LOGGER.debug("Initializing DateRangeCacheRedisSortedSetHelper bean");
        DateRangeCacheRedisSortedSetHelper dateRangeCacheRedisSortedSetHelper = new DateRangeCacheRedisSortedSetHelper();
        setField(dateRangeCacheRedisSortedSetHelper, "redisson",redissionHa());
        LOGGER.debug("Initializing DateRangeCacheRedisSortedSetHelper bean {}", dateRangeCacheRedisSortedSetHelper);
        return dateRangeCacheRedisSortedSetHelper;
    }

    @Bean
    @Primary
    public CacheManager cacheManager() {
        CacheManager cacheManager = new RedissonSpringCacheManager(redissionHa(),redisCacheExpires());
        return new TransactionAwareCacheManagerProxy( cacheManager );
    }

    @Override
    public CacheErrorHandler errorHandler()
    {
        return new PcapCacheErrorHandler();
    }

    @Bean
    public CacheManagerHelper cacheManagerHelper()
    {
        return new CacheManagerHelper();
    }
}


package com.personalcapital.cache.testframework;

import com.personalcapital.cache.aop.*;
import com.personalcapital.cache.config.CacheJVMConfiguration;
import com.personalcapital.cache.redis.DateRangeCacheRedisHashMapUtils;
import com.personalcapital.cache.redis.DateRangeCacheRedisSortedSetHelper;
import com.personalcapital.cache.redis.PcapCacheErrorHandler;
import com.personalcapital.cache.utils.CacheConstants;
import com.personalcapital.cache.utils.CacheManagerHelper;
import com.personalcapital.log.PcapLogger;
import com.personalcapital.log.PcapLoggerFactory;
import org.redisson.api.RedissonClient;
import org.redisson.spring.cache.CacheConfig;
import org.redisson.spring.cache.RedissonSpringCacheManager;
import org.springframework.beans.factory.annotation.Lookup;
import org.springframework.cache.CacheManager;
import org.springframework.cache.annotation.CachingConfigurerSupport;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.cache.interceptor.CacheErrorHandler;
import org.springframework.cache.transaction.TransactionAwareCacheManagerProxy;
import org.springframework.context.annotation.*;
import org.springframework.test.context.TestPropertySource;
import org.testcontainers.containers.GenericContainer;
import org.testcontainers.containers.wait.strategy.Wait;

import jakarta.annotation.PostConstruct;
import jakarta.annotation.PreDestroy;
import java.util.Map;

import static org.springframework.test.util.ReflectionTestUtils.setField;

@Configuration
@EnableAspectJAutoProxy
@EnableCaching(order = org.springframework.core.Ordered.HIGHEST_PRECEDENCE)
@ComponentScan(basePackages = { "com.personalcapital.cache.config" })
@TestPropertySource(properties =
{
        "caching.redis.readMode=MASTER",
        "caching.redis.ha.readMode=MASTER",
        "caching.redisson.idleConnectionTimeout=100",
        "caching.redisson.timeout=2000",
        "caching.redis.timeout=5000",
        "caching.redisson.timeout=5000",
        "caching.redis.pool.maxTotal=50",
        "caching.redis.pool.maxIdle=20",
        "caching.redis.pool.minIdle=5",
        "caching.redis.serializer.useMinBin=false",
        "redis.enabled=true",
        "caching.global.disabled=true",
        "caching.global.mode=redis",
        "caching.redis.hostname=127.0.0.1"
} )
@Import(CacheJVMConfiguration.class)
public class CacheTestConfiguration extends CachingConfigurerSupport
{
    private static final PcapLogger LOGGER = PcapLoggerFactory.getPcapLogger(CacheTestConfiguration.class);
    public static GenericContainer redis =
            new GenericContainer("redis:6")
                    .withExposedPorts(6379);

    public CacheTestConfiguration()
    {
    }

    @PostConstruct
    public void initialize() throws Exception
    {
        LOGGER.debug("CacheTestConfiguration Initialized---" + Thread.currentThread().getName());
        redis.withLogConsumer(new PCAPLogConsumer(LOGGER)).
        waitingFor(
            Wait.forLogMessage(".*Ready to accept connections.*\\n", 1)
        );
        redis.start();
        Thread.sleep(2000);// TODO: Handle proper container startup
        Integer firstMappedPort = redis.getMappedPort(6379);
        final String redisPort = String.valueOf(firstMappedPort);

        System.setProperty("caching.redis.port", redisPort);
        System.setProperty("caching.redis.ha.port", redisPort);
        System.setProperty("caching.redis.ha.cluster.port", redisPort);
        System.setProperty("caching.redis.cluster.port",redisPort);
        System.setProperty("caching.redis.ha.hostname","127.0.0.1");
        System.setProperty("caching.redis.ha.configEndpoint","127.0.0.1");
        System.setProperty("caching.global.uri","127.0.0.1:11211");
        System.setProperty("caching.redis.clusterMode","false");

    }
    @PreDestroy
    public void destroy() throws Exception
    {
        LOGGER.debug("CacheTestConfiguration Destroy---" + Thread.currentThread().getName());
        redis.stop();
    }
    @Lookup(value = CacheConstants.REDISSON_REGULAR)
    public RedissonClient redission(){
        return null;
    }

    @Lookup(value = CacheConstants.REDISSON_HIGH_AVAILABILITY)
    public RedissonClient redissionHa(){
        return null;
    }

    @Lookup(value = "redisCacheExpires")
    public Map<String, CacheConfig> redisCacheExpires()
    {
        return null;
    }

    @Bean
    public PcapCacheableAdvice pcapCacheableAdvice()
    {
        LOGGER.debug("Initializing PcapCacheableAdvice bean");
        PcapCacheableAdvice pcapCacheableAdvice = new PcapCacheableAdvice();
        setField(pcapCacheableAdvice, "redissonGen",redission());
        setField(pcapCacheableAdvice, "redissonHa",redissionHa());
        setField(pcapCacheableAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapCacheableAdvice bean {} " , pcapCacheableAdvice);
        return pcapCacheableAdvice;
    }

    @Bean(name = "pcapMultiCacheableAdvice")
    public PcapMultiCacheableAdvice pcapMultiCacheableAdvice()
    {
        LOGGER.debug("Initializing PcapMultiCacheableAdvice bean");
        PcapMultiCacheableAdvice pcapMultiCacheableAdvice = new PcapMultiCacheableAdvice();
        setField(pcapMultiCacheableAdvice, "redissonGen",redission());
        setField(pcapMultiCacheableAdvice, "redissonHa",redissionHa());
        setField(pcapMultiCacheableAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapCacheableAdvice bean {} " , pcapMultiCacheableAdvice);
        return pcapMultiCacheableAdvice;
    }

    @Bean(name = "pcapMultiCacheEvictAdvice")
    public PcapMultiCacheEvictAdvice pcapMultiCacheEvictAdvice()
    {
        LOGGER.debug("Initialized PcapMultiCacheEvictAdvice bean ");
        PcapMultiCacheEvictAdvice pcapMultiCacheEvictAdvice = new PcapMultiCacheEvictAdvice();
        setField(pcapMultiCacheEvictAdvice, "redissonGen",redission());
        setField(pcapMultiCacheEvictAdvice, "redissonHa",redissionHa());
        setField(pcapMultiCacheEvictAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapMultiCacheEvictAdvice bean {} " , pcapMultiCacheEvictAdvice);
        return pcapMultiCacheEvictAdvice;
    }

    @Bean(name = "pcapMultiCachePutAdvice")
    public PcapMultiCachePutAdvice pcapMultiCachePutAdvice()
    {
        LOGGER.debug("Initialized PcapMultiCachePutAdvice bean ");
        PcapMultiCachePutAdvice pcapMultiCachePutAdvice = new PcapMultiCachePutAdvice();
        setField(pcapMultiCachePutAdvice, "redissonGen",redission());
        setField(pcapMultiCachePutAdvice, "redissonHa",redissionHa());
        setField(pcapMultiCachePutAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapMultiCachePutAdvice bean {} " , pcapMultiCachePutAdvice);
        return pcapMultiCachePutAdvice;
    }

    @Bean
    public PcapCacheEvictAdvice pcapCacheEvictAdvice()
    {
        LOGGER.debug("Initialized PcapCacheEvictAdvice bean ");
        PcapCacheEvictAdvice pcapCacheableEvictAdvice = new PcapCacheEvictAdvice();
        setField(pcapCacheableEvictAdvice, "redissonGen",redission());
        setField(pcapCacheableEvictAdvice, "redissonHa",redissionHa());
        setField(pcapCacheableEvictAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapCacheEvictAdvice bean {} " , pcapCacheableEvictAdvice);
        return pcapCacheableEvictAdvice;
    }

    @Bean
    public PcapCachePutAdvice pcapCachePutAdvice()
    {
        LOGGER.debug("Initialized PcapCachePutAdvice bean " );
        PcapCachePutAdvice pcapCachePutAdvice = new PcapCachePutAdvice();
        setField(pcapCachePutAdvice, "redissonGen",redission());
        setField(pcapCachePutAdvice, "redissonHa",redissionHa());
        setField(pcapCachePutAdvice, "redisCacheExpires",redisCacheExpires());
        LOGGER.debug("Initialized PcapCachePutAdvice bean {} ", pcapCachePutAdvice );
        return pcapCachePutAdvice;
    }


    @Bean
    public DateRangeCacheAdvice dateRangeCacheAdvice()
    {
        LOGGER.debug("Initializing DateRangeCacheAdvice bean");
        DateRangeCacheAdvice dateRangeCacheAdvice = new DateRangeCacheAdvice();
        LOGGER.debug("Initializing DateRangeCacheAdvice bean {} ", dateRangeCacheAdvice);
        return dateRangeCacheAdvice;
    }

    @Bean
    public DateRangeCacheRedisHashMapUtils dateRangeCacheRedisHashMapUtils()
    {
        LOGGER.debug("Initializing DateRangeCacheRedisHashMapUtils bean");
        DateRangeCacheRedisHashMapUtils dateRangeCacheRedisHashMapUtils = new DateRangeCacheRedisHashMapUtils();
        setField(dateRangeCacheRedisHashMapUtils, "redisson",redissionHa());
        LOGGER.debug("Initializing DateRangeCacheRedisHashMapUtils bean {}", dateRangeCacheRedisHashMapUtils);
        return dateRangeCacheRedisHashMapUtils;
    }

    @Bean
    public DateRangeCacheRedisSortedSetHelper dateRangeCacheRedisSortedSetHelper()
    {
        LOGGER.debug("Initializing DateRangeCacheRedisSortedSetHelper bean");
        DateRangeCacheRedisSortedSetHelper dateRangeCacheRedisSortedSetHelper = new DateRangeCacheRedisSortedSetHelper();
        setField(dateRangeCacheRedisSortedSetHelper, "redisson",redissionHa());
        LOGGER.debug("Initializing DateRangeCacheRedisSortedSetHelper bean {}", dateRangeCacheRedisSortedSetHelper);
        return dateRangeCacheRedisSortedSetHelper;
    }

    @Bean
    @Primary
    public CacheManager cacheManager() {
        CacheManager cacheManager = new RedissonSpringCacheManager(redissionHa(),redisCacheExpires());
        return new TransactionAwareCacheManagerProxy( cacheManager );
    }

    @Override
    public CacheErrorHandler errorHandler()
    {
        return new PcapCacheErrorHandler();
    }

    @Bean
    public CacheManagerHelper cacheManagerHelper()
    {
        return new CacheManagerHelper();
    }
}


check out this if it helps

package com.personalcapital.cache.aop;

import java.lang.reflect.Method;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

import org.apache.commons.lang3.ObjectUtils;
import org.apache.commons.lang3.StringUtils;
import org.apache.commons.lang3.exception.ExceptionUtils;
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.springframework.aop.AopInvocationException;
import org.springframework.beans.PropertyAccessorFactory;
import org.springframework.core.annotation.Order;

import com.personalcapital.cache.annotation.PcapMultiCacheable;
import com.personalcapital.cache.annotation.RedisType;
import com.personalcapital.cache.aop.support.AnnotationOrderConstants;
import com.personalcapital.cache.aop.support.CacheAdviceHelper;
import com.personalcapital.cache.aop.support.CacheKeyProvider;
import com.personalcapital.cache.utils.CacheUtils;
import com.personalcapital.log.PcapLogger;
import com.personalcapital.log.PcapLoggerFactory;
import com.safepage.util.Utils;
import io.micrometer.core.instrument.Metrics;

@Aspect
@Order(AnnotationOrderConstants.CACHE_MULTI_CACHING_PRECEDENCE)
public class PcapMultiCacheableAdvice extends CacheAdviceCommons
{
	private static final PcapLogger logger = PcapLoggerFactory
			.getPcapLogger(PcapMultiCacheableAdvice.class);
	private static final String METRICS_NAME = "pcap.cache.event";

	void publishCacheMetrics(ProceedingJoinPoint pjp, String outcome)
	{
		String className = getClassName(pjp);
		String methodName = getMethodName(pjp);

		Metrics.counter(METRICS_NAME, "class", className, "method", methodName, "outcome", outcome)
				.increment();
		logger.info("Publishing cache metrics - Class: {}, Method: {}, Outcome: {}", className,
				methodName, outcome);
	}

	private String getClassName(ProceedingJoinPoint pjp)
	{
		return pjp.getTarget()
				.getClass()
				.getSimpleName();
	}

	private String getMethodName(ProceedingJoinPoint pjp)
	{
		return pjp.getSignature()
				.getName();
	}

	@SuppressWarnings("unchecked")
	@Around("@annotation(pcapMultiCacheable)")
	public Object doMultiCacheable(ProceedingJoinPoint pjp, PcapMultiCacheable pcapMultiCacheable)
			throws Throwable
	{
		String className = getClassName(pjp);
		String methodName = getMethodName(pjp);

		Method method = null;
		Object[] args = pjp.getArgs();
		Class<?> returnType = null;
		Integer listKeyArgIndex = null;
		Collection<Object> listKeyArg = new ArrayList<Object>();
		Collection<Object> otherKeyArgs = new ArrayList<Object>();

		Collection<Object> missedListKeys = null;
		Object[] modifiedArgs = null;
		boolean resultIsCollection = true;

		String resultKeyField = pcapMultiCacheable.resultKeyField();
		String[] resultKeyFields = pcapMultiCacheable.resultKeyFields();

		boolean cachedValueNullable = pcapMultiCacheable.nullable();
		String keyPrefix = pcapMultiCacheable.keyPrefix();
		Collection<Object> collectionResult = null;
		Map<Object, Object> mapResult = null;

		Map<Object, Object> keyValueMap = new LinkedHashMap<>();
		String cacheName = pcapMultiCacheable.value();
		RedisType redisType = pcapMultiCacheable.redisType();
		// get type of cache: default or redis or simple from annotation
		if (StringUtils.isBlank(cacheName))
		{
			throw new AopInvocationException(
					"pcapMultiCacheable needs to have cacheName specified in value element.");
		}
		CacheKeyProvider cacheKeyProvider = pcapMultiCacheable.keyProvider()
				.getDeclaredConstructor()
				.newInstance();
		try
		{
			method = CacheAdviceHelper.getMethod(pjp);
			returnType = method.getReturnType();

			// check expected return type
			if (Collection.class.isAssignableFrom(returnType))
			{
				resultIsCollection = true;
				collectionResult = collectionInstance((Class<? extends Collection>) returnType);
			}
			else if (Map.class.isAssignableFrom(returnType))
			{
				resultIsCollection = false;
				mapResult = mapInstance((Class<? extends Map>) returnType);
			}
			else
			{
				throw new AopInvocationException(
						"pcapMultiCacheable cannot apply to method without return.");
			}

			// check if keyIndices are provided for keyName generation
			int[] keyIndice = pcapMultiCacheable.keys();

			if (args == null || args.length == 0)
			{
				throw new AopInvocationException(
						"pcapMultiCacheable cannot apply to method without parameter");
			}

			// get other Arguments to generate key
			if (keyIndice == null || keyIndice.length == 0)
			{
				for (int i = 0; i < args.length; i++)
				{
					Object arg = args[i];
					/*
					 * if arguments contain a collection, remember the argument number tp extract
					 * elements for keyName generation later
					 */
					if (Collection.class.isInstance(arg)
							&& Collection.class.isAssignableFrom(arg.getClass()))
					{
						listKeyArgIndex = i;
					}
					else
					{
						otherKeyArgs.add(cacheKeyProvider.getKeyField(arg));
					}
				}
			}
			else
			{
				// if we provide a list of indices for the args that have to be used for keys, use
				// this to generate keys
				for (int keyIndex : keyIndice)
				{
					if (keyIndex >= args.length)
						continue;

					Object arg = args[keyIndex];
					if (Collection.class.isInstance(arg)
							&& Collection.class.isAssignableFrom(arg.getClass()))
					{
						listKeyArgIndex = keyIndex;
					}
					else
					{
						otherKeyArgs.add(cacheKeyProvider.getKeyField(arg));
					}
				}
			}

			if (listKeyArgIndex == null)
			{
				throw new AopInvocationException(
						"pcapMultiCacheable must have a Collection parameter as key list");
			}

			// get the collection arg to generate keys
			listKeyArg = (Collection<Object>) args[listKeyArgIndex];
			for (Object listKey : listKeyArg)
			{
				// get key generated from all values gathered so far from pcapMultiCacheable
				String key = CacheUtils.generateKey(cacheName, keyPrefix,
						cacheKeyProvider.getKeyField(listKey), otherKeyArgs);
				// get cachedValue
				Object cachedValue = getRedisson(redisType).getBucket(key)
						.get();
				if (cachedValue == null || (cachedValue instanceof ObjectUtils.Null
						&& cachedValueNullable == false))
				{
					if (missedListKeys == null)
					{
						// create an empty collection of type of expected cachedValues
						missedListKeys = collectionInstance(listKeyArg.getClass());
					}

					// create a collection of keys with no cachedValues
					((Collection<Object>) missedListKeys).add(listKey);
					// Cache Miss Metric
					publishCacheMetrics(pjp, "miss");
				}
				else
				{
					// write keys and corresponding cached values to a keyValue Map
					((Map<Object, Object>) keyValueMap).put(listKey,
							CacheUtils.getValue(cachedValue));
					// Cache Hit Metric
					publishCacheMetrics(pjp, "hit");
				}
			}

			// if there are no missed keys just return all the values fetched from cache
			if (missedListKeys == null || missedListKeys.isEmpty())
			{
				if (resultIsCollection)
					return getCollectionResult(listKeyArg, keyValueMap, collectionResult);
				else
					return getMapResult(listKeyArg, keyValueMap, mapResult);
			}

			// here we update the arguments for the method to only get those records from the db for
			// which we didn't find an entry in the cache.
			modifiedArgs = modifiedArgs(args, listKeyArgIndex, missedListKeys);
		}
		catch (Exception ex)
		{
			logger.info("Caching on {} aborted due to an error. message: {}. stacktrace: {}",
					pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
			// Cache Failure Metric
			publishCacheMetrics(pjp, "failure");
			try
			{
				final CacheKeyProvider finalCacheKeyProvider = cacheKeyProvider;
				final Collection<Object> finalOtherKeyArgs = otherKeyArgs;
				List<String> keys = listKeyArg.stream()
						.filter(k -> Objects.nonNull(k))
						.map(k -> CacheUtils.generateKey(cacheName, keyPrefix,
								finalCacheKeyProvider.getKeyField(k), finalOtherKeyArgs))
						.collect(Collectors.toList());
				if (!evictFromRedis(redisType, keys))
				{
					// if eviction fails we fetch from db and return
					return pjp.proceed();
				}
			}
			catch (Exception e)
			{
				logger.info("Eviction on caching failure failed on {}, due to: {}, stacktrace: {}",
						pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
				// Cache Eviction Failure Metric
				publishCacheMetrics(pjp, "eviction_failure");
			}
			// since we evict all the keys we want to fetch and save all the keys again
			modifiedArgs = args;
		}

		/*
		 * so far we have created a key and gotten the corresponding cached values for these keys we
		 * also have a list of all the keys for which we don't have a value.
		 */
		final Object resultForMissed = pjp.proceed(modifiedArgs);

		int ttlSeconds = getTtlFromConfiguration(cacheName, pcapMultiCacheable.ttlSeconds());

		// we now have all the missing collection/data from the database
		try
		{
			if (resultIsCollection)
			{
				// get all the newly fetched data
				Collection<Object> collectionResultForMissed = (Collection<Object>) resultForMissed;

				// check if something from the result has to be used as part of the key.
				if (Utils.isNotNull(resultKeyField)
						|| (resultKeyFields != null && resultKeyFields.length > 0))
				{
					Collection<Object> mergedResult = getCollectionResult(listKeyArg, keyValueMap,
							collectionResult);

					// if nothing new was found for the missed keys, just return the existing
					// collection
					if (collectionResultForMissed == null || collectionResultForMissed.isEmpty())
						return mergedResult;

					List<Object> keyFieldValues = new ArrayList<Object>();

					for (Object resultItemForMissed : collectionResultForMissed)
					{
						if (resultItemForMissed == null)
							continue;

						keyFieldValues.clear();
						if ((resultKeyFields != null && resultKeyFields.length > 0))
						{
							// if key is to be derived from result, then get the field from result
							// using reflection and create the cache key
							for (int i = 0; i < resultKeyFields.length; i++)
							{
								Object keyFieldValue = PropertyAccessorFactory
										.forBeanPropertyAccess(resultItemForMissed)
										.getPropertyValue(resultKeyFields[i]);
								keyFieldValues.add(cacheKeyProvider.getKeyField(keyFieldValue));
							}
						}
						else
						{// is only one is property is given use that value for key directly
							Object keyFieldValue = PropertyAccessorFactory
									.forBeanPropertyAccess(resultItemForMissed)
									.getPropertyValue(resultKeyField);

							if (keyFieldValue != null)
							{
								keyFieldValues.add(cacheKeyProvider.getKeyField(keyFieldValue));
							}
						}

						// genearteKey and add the item fetched from db.
						if (keyFieldValues.size() > 0)
						{
							String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix,
									keyFieldValues, otherKeyArgs);
							getRedisson(redisType).getBucket(cacheKey)
									.set(resultItemForMissed, ttlSeconds, TimeUnit.SECONDS);
							// Cache Store Metric
							publishCacheMetrics(pjp, "store");
						}
						// add found item to resultant collection from cache+db that has to be
						// returned
						mergedResult.add(resultItemForMissed);
					}

					return mergedResult;
				}

				// if all the generated keys don't have a corresponding value, just generate a list
				// for the ones that do have it
				if (collectionResultForMissed == null
						|| collectionResultForMissed.size() != missedListKeys.size())
				{
					logger.warn(
							"Did not receive a correlated amount of data from the target method: {}. "
									+ "Result list will be unsorted and won't respect the order of the keys passed in argument.",
							pjp.toShortString());
					// Data Mismatch Metric
					publishCacheMetrics(pjp, "data_mismatch");
					Collection<Object> resultFromHit = getCollectionResult(listKeyArg, keyValueMap,
							collectionResult);
					if (collectionResultForMissed != null)
					{
						collectionResultForMissed.addAll(resultFromHit);
						return collectionResultForMissed;
					}
					return resultFromHit;
				}

				// if no property of the resulting objects from the object collection has to be used
				// as part of they key, simply iterate over the missedKeys and missed Values and
				// create a resultant collection and return it.

				Iterator<Object> missedValueIterator = collectionResultForMissed.iterator();
				Iterator<Object> missedKeyIterator = missedListKeys.iterator();

				while (missedKeyIterator.hasNext())
				{
					Object key = missedKeyIterator.next();
					Object value = missedValueIterator.next();

					if (value != null || cachedValueNullable)
					{
						String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix,
								cacheKeyProvider.getKeyField(key), otherKeyArgs);
						getRedisson(redisType).getBucket(cacheKey)
								.set(value == null ? ObjectUtils.NULL : value, ttlSeconds,
										TimeUnit.SECONDS);
						// Cache Store Metric
						publishCacheMetrics(pjp, "store");
					}

					keyValueMap.put(key, value);
				}

				// return a collection of missing objects
				return getCollectionResult(listKeyArg, keyValueMap, collectionResult);
			}
			else
			{
				// if result is a map and not a collection
				Map<Object, Object> mapResultForMissed = (Map<Object, Object>) resultForMissed;
				Map<Object, Object> mergedResult = getMapResult(listKeyArg, keyValueMap, mapResult);
				if (mapResultForMissed == null || mapResultForMissed.isEmpty())
				{
					return mergedResult;
				}

				Iterator<Object> missedKeyIterator = missedListKeys.iterator();

				while (missedKeyIterator.hasNext())
				{
					Object key = missedKeyIterator.next();
					Object value = mapResultForMissed.get(key);

					if (value != null || cachedValueNullable)
					{
						String cacheKey = CacheUtils.generateKey(cacheName, keyPrefix,
								cacheKeyProvider.getKeyField(key), otherKeyArgs);
						getRedisson(redisType).getBucket(cacheKey)
								.set(value == null ? ObjectUtils.NULL : value, ttlSeconds,
										TimeUnit.SECONDS);
						// Cache Store Metric
						publishCacheMetrics(pjp, "store");
					}

					mergedResult.put(key, value);
				}

				return mergedResult;
			}
		}
		catch (Exception ex)
		{
			logger.info("Caching on {} aborted due to an error. message: {}. stacktrace: {}",
					pjp.toShortString(), ex.getMessage(), ExceptionUtils.getStackTrace(ex));
			// Cache Failure Metric
			publishCacheMetrics(pjp, "failure");

			return pjp.proceed();
		}
	}

	private Object[] modifiedArgs(final Object[] originalArgs, int listKeyIndex,
			Collection<Object> missedListKeys)
	{
		Object[] modifiedArgs = new Object[originalArgs.length];
		System.arraycopy(originalArgs, 0, modifiedArgs, 0, originalArgs.length);

		modifiedArgs[listKeyIndex] = missedListKeys;
		return modifiedArgs;
	}

	private Collection<Object> getCollectionResult(Collection<Object> listKeyArg,
			Map<Object, Object> keyValueMap, Collection<Object> collectionResult)
	{
		collectionResult.clear();

		for (Object listKey : listKeyArg)
		{
			if (keyValueMap.containsKey(listKey))
				collectionResult.add(keyValueMap.get(listKey));
		}

		return collectionResult;
	}

	/**
	 * get list of arguments and results for map and create a resultant merged cache+db map
	 * 
	 * @param listKeyArg
	 * @param keyValueMap
	 * @param mapResult
	 * @return
	 */
	private Map<Object, Object> getMapResult(Collection<Object> listKeyArg,
			Map<Object, Object> keyValueMap, Map<Object, Object> mapResult)
	{
		mapResult.clear();

		for (Object listKey : listKeyArg)
		{
			if (keyValueMap.containsKey(listKey))
				mapResult.put(listKey, keyValueMap.get(listKey));
		}

		return mapResult;
	}

	/**
	 * return a new collection instance with a given type
	 * 
	 * @param listType
	 * @return
	 */
	private Collection<Object> collectionInstance(Class<? extends Collection> listType)
	{
		Collection<Object> listInstance;

		try
		{
			listInstance = listType.getDeclaredConstructor()
					.newInstance();
		}
		catch (Throwable e)
		{
			listInstance = new ArrayList<>();
		}

		return listInstance;
	}

	/**
	 * return a new map instance of map type with given non-generic types
	 * 
	 * @param mapType
	 * @return
	 */
	private Map<Object, Object> mapInstance(Class<? extends Map> mapType)
	{
		Map<Object, Object> mapInstance;

		try
		{
			mapInstance = mapType.getDeclaredConstructor()
					.newInstance();
		}
		catch (Throwable e)
		{
			mapInstance = new LinkedHashMap<>();
		}

		return mapInstance;
	}
}

package com.personalcapital.cache.aop;

import com.personalcapital.cache.annotation.PcapMultiCacheable;
import com.personalcapital.cache.annotation.RedisType;
import com.personalcapital.cache.aop.support.CacheAdviceHelper;
import com.personalcapital.cache.aop.support.CacheKeyProvider;
import com.personalcapital.cache.utils.CacheConstants;
import io.micrometer.core.instrument.Counter;
import io.micrometer.core.instrument.Metrics;
import io.micrometer.core.instrument.simple.SimpleMeterRegistry;

import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.Signature;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.mockito.*;
import org.redisson.api.RBucket;
import org.redisson.api.RedissonClient;
import org.redisson.spring.cache.CacheConfig;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.cache.CacheManager;
import org.springframework.context.annotation.Bean;
import org.springframework.test.context.junit.jupiter.SpringJUnitConfig;

import java.lang.reflect.Method;
import java.util.Collections;
import java.util.HashMap;
import java.util.Map;

import static com.personalcapital.cache.utils.CacheConstants.FLOW_CACHE;
import static com.personalcapital.cache.utils.CacheConstants.FLOW_CACHE_TTL_IN_SECONDS;
import static java.util.concurrent.TimeUnit.SECONDS;
import static org.mockito.Mockito.*;
import static org.junit.jupiter.api.Assertions.*;

@SpringJUnitConfig(locations =
{
		"classpath:cachePushAdviceTest-Context.xml"
})
public class PcapMultiCacheableAdviceTestCacheHit
{

	@InjectMocks
	@Spy
	@Autowired
	private PcapMultiCacheableAdvice cacheAdvice;

	private SimpleMeterRegistry meterRegistry;
	private PcapMultiCacheable mockAnnotation;

	@Autowired
	@Qualifier(CacheConstants.REDISSON_REGULAR)
	private RedissonClient redissonClient;

	@Autowired
	@Qualifier(CacheConstants.REDIS_CACHE_MANAGER_REGULAR)
	private CacheManager cacheManager;

	@Bean(name = "redisCacheExpires")
	public Map<String, CacheConfig> redisCacheExpires()
	{
		Map<String, CacheConfig> config = new HashMap<>();
		/*
		 * create "securityInfo" cache with ttl =7,200,000ms(7200s) and maxIdleTime = 0ms
		 * maxIdleTime will expire the key sooner than the ttl, if the item hasn't been "touched" in
		 * that much duration
		 */
		// TODO : This needs to move out
		config.put("securityInfo", new CacheConfig(SECONDS.toMillis(7200), 0));
		config.put("quote", new CacheConfig(SECONDS.toMillis(600), 0));
		config.put("historicalQuote", new CacheConfig(SECONDS.toMillis(86400), 0));
		config.put("advice", new CacheConfig(SECONDS.toMillis(1800), 0));
		config.put("adviceData", new CacheConfig(SECONDS.toMillis(10800), 0));
		config.put("entity", new CacheConfig(SECONDS.toMillis(1800), 0));
		config.put("security", new CacheConfig(SECONDS.toMillis(3600), 0));
		config.put("yodlee", new CacheConfig(SECONDS.toMillis(1800), 0));
		config.put("userFeature", new CacheConfig(SECONDS.toMillis(300), 0));
		config.put("messageTemplateData", new CacheConfig(SECONDS.toMillis(864000), 0));
		config.put("frontapp", new CacheConfig(SECONDS.toMillis(1800), 0));
		config.put(FLOW_CACHE, new CacheConfig(SECONDS.toMillis(FLOW_CACHE_TTL_IN_SECONDS), 0));
		return config;
	}

	@BeforeEach
	void setUp()
	{
		MockitoAnnotations.openMocks(this);

		meterRegistry = new SimpleMeterRegistry();
		Metrics.addRegistry(meterRegistry);

		redissonClient = mock(RedissonClient.class);
		RBucket<Object> mockBucket = mock(RBucket.class);
		when(redissonClient.getBucket(anyString())).thenReturn(mockBucket);
		when(mockBucket.get()).thenReturn(null); // Simulate cache hit

		mockAnnotation = mock(PcapMultiCacheable.class);
		when(mockAnnotation.value()).thenReturn("testCache");
		when(mockAnnotation.keys()).thenReturn(new int[]{0});
		when(mockAnnotation.keyPrefix()).thenReturn("prefix");
		when(mockAnnotation.redisType()).thenReturn(RedisType.DEFAULT);
		when(mockAnnotation.keyProvider()).thenAnswer(invocation -> DummyCacheKeyProvider.class);
		try (MockedStatic<CacheAdviceHelper> mockedStatic = mockStatic(CacheAdviceHelper.class)){
			Method mockMethod = DummyClass.class.getMethod("dummyMethod");
			mockedStatic.when(()-> CacheAdviceHelper.getMethod(any(ProceedingJoinPoint.class))).thenReturn(mockMethod);
		}
		catch (NoSuchMethodException e)
		{
			throw new RuntimeException("Failed to mock getMethod",e);
		}
	}

	public static class DummyClass{
		public void dummyMethod(){}
	}

	@Test
	void testCacheHitMetricThroughDoMultiCacheable() throws Throwable
	{
		ProceedingJoinPoint pjp = mockProceedingJoinPoint();
		try (MockedStatic<Metrics> mockedMetrics = Mockito.mockStatic(Metrics.class))
		{
			Counter mockCounter = mock(Counter.class);
			mockedMetrics.when(() -> Metrics.counter(anyString(), any(String[].class)))
					.thenReturn(mockCounter);

			Object result = cacheAdvice.doMultiCacheable(pjp, mockAnnotation);

			assertNotNull(result);
			assertEquals("cachedValue", result);

			mockedMetrics.verify(() -> Metrics.counter("pcap.cache.event", "class",
					"PcapMultiCacheableAdvice", "method", "testMethod", "outcome", "hit"),
					times(1));

			verify(mockCounter, times(1)).increment();
		}
	}

	@Test
	void testCacheMiss() throws Throwable
	{
		ProceedingJoinPoint pjp = mockProceedingJoinPoint();

		try (MockedStatic<Metrics> mockedMetrics = Mockito.mockStatic(Metrics.class))
		{
			Counter mockCounter = mock(Counter.class);
			mockedMetrics.when(() -> Metrics.counter(anyString(), any(String[].class)))
					.thenReturn(mockCounter);

			Object result = cacheAdvice.doMultiCacheable(pjp, mockAnnotation);

			assertNotNull(result);
			assertEquals("dbFetchedValue", result);

			ArgumentCaptor<String> outcome = ArgumentCaptor.forClass(String.class);
			mockedMetrics.verify(() -> Metrics.counter(
					eq("pcap.cache.event"), eq("class"),
							eq("PcapMultiCacheableAdvice"), eq("method"), eq("testMethod"), eq("outcome"), outcome.capture()),
					times(1));
			String actualOutcome = outcome.getValue();
			System.out.println("Actual Metric Outcome: " + actualOutcome);
			assertTrue(actualOutcome.equals("miss") || actualOutcome.equals("failure") || actualOutcome.equals("data_mismatch"));
			verify(mockCounter, times(1)).increment();
		}
	}

	private ProceedingJoinPoint mockProceedingJoinPoint() throws Throwable
	{
		ProceedingJoinPoint pjp = mock(ProceedingJoinPoint.class);
		Signature mockSignature = mock(Signature.class);
		when(pjp.getTarget()).thenReturn(cacheAdvice);
		when(pjp.getSignature()).thenReturn(mockSignature);
		when(mockSignature.getName()).thenReturn("testMethod");
		when(pjp.getArgs()).thenReturn(new Object[]
		{
				Collections.singletonList("key1")
		});
		when(pjp.proceed()).thenReturn("dbFetchedValue");
		return pjp;
	}

	public static class DummyCacheKeyProvider implements CacheKeyProvider
	{
		@Override
		public Object getKeyField(Object value)
		{
			return value != null ? value.toString() : "null";
		}
	}
}

org.opentest4j.AssertionFailedError: 
Expected :cachedValue
Actual   :dbFetchedValue
<Click to see difference>


	at org.junit.jupiter.api.AssertionFailureBuilder.build(AssertionFailureBuilder.java:151)
	at org.junit.jupiter.api.AssertionFailureBuilder.buildAndThrow(AssertionFailureBuilder.java:132)
	at org.junit.jupiter.api.AssertEquals.failNotEqual(AssertEquals.java:197)
	at org.junit.jupiter.api.AssertEquals.assertEquals(AssertEquals.java:182)
	at org.junit.jupiter.api.AssertEquals.assertEquals(AssertEquals.java:177)
	at org.junit.jupiter.api.Assertions.assertEquals(Assertions.java:1145)
	at com.personalcapital.cache.aop.PcapMultiCacheableAdviceTestCacheHit.testCacheHitMetricThroughDoMultiCacheable(PcapMultiCacheableAdviceTestCacheHit.java:131)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)


org.mockito.exceptions.verification.TooManyActualInvocations: 
Metrics.class.counter(
    "pcap.cache.event",
    "class",
    "PcapMultiCacheableAdvice",
    "method",
    "testMethod",
    "outcome",
    <Capturing argument: String>
);
Wanted 1 time:
-> at io.micrometer.core.instrument.Metrics.counter(Metrics.java:76)
But was 3 times:
-> at com.personalcapital.cache.aop.PcapMultiCacheableAdvice.publishCacheMetrics(PcapMultiCacheableAdvice.java:48)
-> at com.personalcapital.cache.aop.PcapMultiCacheableAdvice.publishCacheMetrics(PcapMultiCacheableAdvice.java:48)
-> at com.personalcapital.cache.aop.PcapMultiCacheableAdvice.publishCacheMetrics(PcapMultiCacheableAdvice.java:48)



	at io.micrometer.core.instrument.Metrics.counter(Metrics.java:76)
	at com.personalcapital.cache.aop.PcapMultiCacheableAdviceTestCacheHit.lambda$testCacheMiss$5(PcapMultiCacheableAdviceTestCacheHit.java:158)
	at com.personalcapital.cache.aop.PcapMultiCacheableAdviceTestCacheHit.testCacheMiss(PcapMultiCacheableAdviceTestCacheHit.java:158)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)


Process finished with exit code 255

